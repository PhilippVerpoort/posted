{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"../R/masking.R\")\n",
    "source(\"../R/tedf.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"hi\"\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "library(posted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in unit_convert(\"kW\", \"kWh\"):\n",
      "\"No conversion factor found for unit 'kW' to 'kWh'.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;NA&gt;"
      ],
      "text/latex": [
       "<NA>"
      ],
      "text/markdown": [
       "&lt;NA&gt;"
      ],
      "text/plain": [
       "[1] NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Information\n",
      "\n",
      "_\bC_\bo_\bn_\bv_\be_\br_\bt_\bs _\bu_\bn_\bi_\bt_\bs _\bw_\bi_\bt_\bh _\bo_\bp_\bt_\bi_\bo_\bn_\ba_\bl _\bf_\bl_\bo_\bw _\bc_\bo_\bn_\bt_\be_\bx_\bt _\bh_\ba_\bn_\bd_\bl_\bi_\bn_\bg _\bb_\ba_\bs_\be_\bd _\bo_\bn _\bs_\bp_\be_\bc_\bi_\bf_\bi_\be_\bd\n",
      "_\bv_\ba_\br_\bi_\ba_\bn_\bt_\bs _\ba_\bn_\bd _\bf_\bl_\bo_\bw _\bI_\bD. _\bT_\bh_\be _\bf_\bu_\bn_\bc_\bt_\bi_\bo_\bn _\bc_\bh_\be_\bc_\bk_\bs _\bi_\bf _\bt_\bh_\be _\bi_\bn_\bp_\bu_\bt _\bu_\bn_\bi_\bt_\bs _\ba_\br_\be _\bn_\bo_\bt\n",
      "_\bN_\ba_\bN, _\bt_\bh_\be_\bn _\bi_\bt _\bp_\br_\bo_\bc_\be_\be_\bd_\bs _\bt_\bo _\bh_\ba_\bn_\bd_\bl_\be _\bd_\bi_\bf_\bf_\be_\br_\be_\bn_\bt _\bc_\ba_\bs_\be_\bs _\bb_\ba_\bs_\be_\bd _\bo_\bn _\bt_\bh_\be _\bp_\br_\be_\bs_\be_\bn_\bc_\be\n",
      "_\bo_\bf _\ba _\bf_\bl_\bo_\bw _\bc_\bo_\bn_\bt_\be_\bx_\bt _\ba_\bn_\bd _\bu_\bn_\bi_\bt _\bv_\ba_\br_\bi_\ba_\bn_\bt_\bs.\n",
      "\n",
      "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
      "\n",
      "     Converts units with optional flow context handling based on\n",
      "     specified variants and flow ID. The function checks if the input\n",
      "     units are not NaN, then it proceeds to handle different cases\n",
      "     based on the presence of a flow context and unit variants.\n",
      "\n",
      "_\bU_\bs_\ba_\bg_\be:\n",
      "\n",
      "     unit_convert(unit_from, unit_to, flow_id = NULL)\n",
      "     \n",
      "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
      "\n",
      "unit_from: Character or numeric. Unit to convert from.\n",
      "\n",
      " unit_to: Character or numeric. Unit to convert to.\n",
      "\n",
      " flow_id: Character or NULL. Identifier for the specific flow or\n",
      "          process.\n",
      "\n",
      "_\bV_\ba_\bl_\bu_\be:\n",
      "\n",
      "     Numeric. Conversion factor between 'unit_from' and 'unit_to'.\n",
      "\n",
      "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
      "\n",
      "     # Example usage:\n",
      "     convert_units(\"m\", \"km\", flow_id = NULL)\n",
      "     "
     ]
    }
   ],
   "source": [
    "unit_convert <- function(unit_from, unit_to, flow_id=NULL) {\n",
    "    #' Converts units with optional flow context handling based on\n",
    "    #' specified variants and flow ID. The function checks if the input units are not NaN,\n",
    "    #' then it proceeds to handle different cases based on the presence of a flow context and unit\n",
    "    #' variants.\n",
    "    #'\n",
    "    #' @param unit_from Character or numeric. Unit to convert from.\n",
    "    #' @param unit_to Character or numeric. Unit to convert to.\n",
    "    #' @param flow_id Character or NULL. Identifier for the specific flow or process.\n",
    "    #'\n",
    "    #' @return Numeric. Conversion factor between \\code{unit_from} and \\code{unit_to}.\n",
    "    #'\n",
    "    #' @examples\n",
    "    #' # Example usage:\n",
    "    #' convert_units(\"m\", \"km\", flow_id = NULL)\n",
    "    #'\n",
    "    #' @export\n",
    "\n",
    "\n",
    "\n",
    "    if(is.na(unit_from) | is.na(unit_to)) {\n",
    "        return(NaN)\n",
    "    }\n",
    "    # if unit_from and unit_to are the same, return 1\n",
    "    if (unit_from == unit_to) {\n",
    "        return(1)\n",
    "    }\n",
    "\n",
    "    # if there is no flow ID take conversion from cached units, else proceed with flow_id\n",
    "    if (is.null(flow_id)) {\n",
    "        values <- dplyr::filter(cached_units, from==unit_from & to==unit_to)\n",
    "        if (nrow(values) == 0) {\n",
    "            warning(sprintf(\"No conversion factor found for unit '%s' to '%s'.\", unit_from, unit_to))\n",
    "        }\n",
    "    } else {\n",
    "        values <- dplyr::filter(cached_units, from==unit_from & to==unit_to & ft==flow_id)\n",
    "\n",
    "        # if there was no match, try again without flow_id\n",
    "        if (nrow(values) == 0) {\n",
    "            values <- dplyr::filter(cached_units, from==unit_from & to==unit_to)\n",
    "        }\n",
    "        # if there was no match at all, report a warning\n",
    "        if (nrow(values) == 0) {\n",
    "            if (is.na(flow_id)) {\n",
    "                warning(sprintf(\"No conversion factor found for unit '%s' to '%s'.\", unit_from, unit_to))\n",
    "            } else {\n",
    "                warning(sprintf(\"No conversion factor found for unit '%s' to '%s' and flow type '%s'.\", unit_from, unit_to, flow_id))\n",
    "            }\n",
    "            return(NA)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # return\n",
    "    return(values$factor[1])\n",
    "}\n",
    "\n",
    "# ?test\n",
    "(unit_convert(\"kW\", \"kWh\"))\n",
    "?unit_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:580:104: Unerwartete(s) ','\n579:             }\n580:             unit_conversion_3_from <- var_units[[gsub(\"|OPEX Fixed Specific\", '|OCF'), row[['variable'],\n                                                                                                            ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:580:104: Unerwartete(s) ','\n579:             }\n580:             unit_conversion_3_from <- var_units[[gsub(\"|OPEX Fixed Specific\", '|OCF'), row[['variable'],\n                                                                                                            ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# source(\"R/posted/masking.R\")\n",
    "# source(\"R/posted/tedf.R\")\n",
    "source(\"R/units.R\")\n",
    "library(dplyr)\n",
    "library(Deriv)\n",
    "\n",
    "\n",
    "\n",
    "# get list of TEDFs potentially containing variable\n",
    "collect_files <- function(parent_variable, include_databases = NULL) {\n",
    "  #' collect_files\n",
    "  #' Takes a parent variable and optional list of databases to include,\n",
    "  #' checks for their existence, and collects files and directories based on the parent variable.\n",
    "  #'\n",
    "  #' @param parent_variable Character. Variable to collect files on.\n",
    "  #' @param include_databases Optional list[Character]. List of Database IDs to collect files from.\n",
    "  #'\n",
    "  #' @return List of tuples. List of tuples containing the parent variable and the\n",
    "  #' database ID for each file found in the specified directories.\n",
    "  #'\n",
    "  #' @examples\n",
    "  #' # Example usage:\n",
    "  #' collect_files(\"variable_name\", c(\"db1\", \"db2\"))\n",
    "  #'\n",
    "  #' @export\n",
    "\n",
    "  if (parent_variable == \"\") {\n",
    "    stop(\"Variable may not be empty.\")\n",
    "  }\n",
    "\n",
    "  # check that the requested database to include can be found\n",
    "  if (!is.null(include_databases)) {\n",
    "    for (database_id in include_databases) {\n",
    "      if (!(database_id %in% names(databases) && file.exists(databases[[database_id]]))) {\n",
    "        stop(paste(\"Could not find database '\", database_id, \"'.\", sep = \"\"))\n",
    "      }\n",
    "    }\n",
    "\n",
    "\n",
    "  }\n",
    "\n",
    "  ret <- list()\n",
    "  for (database_id in names(databases)) {\n",
    "    # skip ted paths not requested to include\n",
    "    if (!is.null(include_databases) && !(database_id %in% include_databases)) next\n",
    "\n",
    "    # find top-level file and directory\n",
    "    top_path <- paste(unlist(strsplit(parent_variable, '\\\\|')), collapse = '/')\n",
    "    top_file <- file.path(databases[[database_id]], 'tedfs', paste(top_path, '.csv', sep = ''))\n",
    "    top_directory <- file.path(databases[[database_id]], 'tedfs', top_path)\n",
    "\n",
    "    # add top-level file if it exists\n",
    "    if (file.exists(top_file) && !dir.exists(top_file)) {\n",
    "      ret <- c(ret, list(list(parent_variable, database_id)))\n",
    "    }\n",
    "\n",
    "    # add all files contained in top-level directory\n",
    "    if (file.exists(top_directory) && dir.exists(top_directory)) {\n",
    "      sub_files <- list.files(top_directory, pattern = '\\\\.csv$', full.names = TRUE, recursive = TRUE)\n",
    "      for (sub_file in sub_files) {\n",
    "        sub_variable <- paste(parent_variable, '|', tools::file_path_sans_ext(file.path(top_directory, sub_file)), sep = '')\n",
    "        ret <- c(ret, list(list(sub_variable, database_id)))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    # loop over levels\n",
    "    levels <- unlist(strsplit(parent_variable, '|'))\n",
    "    for (l in seq_along(levels)) {\n",
    "      # find top-level file and directory\n",
    "      top_path <- paste(levels[seq_len(l)], collapse = '/')\n",
    "      parent_file <- file.path(databases[[database_id]], 'tedfs', paste(top_path, '.csv', sep = ''))\n",
    "\n",
    "      # add parent file if it exists\n",
    "      if (file.exists(parent_file) && file.isFile(parent_file)) {\n",
    "        parent_variable <- paste(levels[seq_len(l)], collapse = '|')\n",
    "        ret <- c(ret, list(list(parent_variable, database_id)))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(ret)\n",
    "}\n",
    "\n",
    "# normalise units\n",
    "normalise_units <- function(df, level, var_units, var_flow_ids) {\n",
    "  #' normalise_units\n",
    "  #'\n",
    "  #' Takes a DataFrame with reported or reference data, along with\n",
    "  #' dictionaries mapping variable units and flow IDs, and normalizes the units of the variables in the\n",
    "  #' DataFrame based on the provided mappings.\n",
    "  #'\n",
    "  #' @param df DataFrame. Dataframe to be normalized.\n",
    "  #' @param level Character. Specifies whether the data should be normalized on the reported or reference values. Possible values are 'reported' or 'reference'.\n",
    "  #' @param var_units List. Dictionary that maps a combination of parent variable and variable to its corresponding unit. The keys in the dictionary are in the format \"{parent_variable}|{variable}\", and the values are the units associated with that variable.\n",
    "  #' @param var_flow_ids List. Dictionary that maps a combination of parent variable and variable to a specific flow ID. This flow ID is used for unit conversion in the \\code{normalize_units} function.\n",
    "  #'\n",
    "  #' @return DataFrame. Normalized dataframe.\n",
    "  #'\n",
    "  #' @examples\n",
    "  #' # Example usage:\n",
    "  #' normalize_dataframe(df, \"reported\", var_units, var_flow_ids)\n",
    "  #'\n",
    "  #' @export\n",
    "\n",
    "  prefix <- ifelse(level == 'reported', '', 'reference_')\n",
    "  var_col_id <- paste0(prefix, 'variable')\n",
    "  value_col_id <- paste0(prefix, 'value')\n",
    "  unit_col_id <- paste0(prefix, 'unit')\n",
    "\n",
    "  target_unit <- apply(df, 1, function(row) {\n",
    "    tryCatch({\n",
    "    ifelse((is.character(row[var_col_id]) && (!(row[var_col_id] == \"\"))),\n",
    "            var_units[[paste0(row['parent_variable'], \"|\", row[var_col_id])]], NA)}, error=function(e){NA})\n",
    "            })\n",
    "\n",
    "  # TODO: make this try catch nicer\n",
    "  target_flow_id <- apply(df, 1, function(row) {\n",
    "\n",
    "    tryCatch({\n",
    "    ifelse((is.character(row[var_col_id]) && (!(row[var_col_id] == \"\"))),\n",
    "            var_flow_ids[[paste0(row['parent_variable'], \"|\", row[var_col_id])]], NA)}, error=function(e){NA}, warning=function(w){NA})\n",
    "            })\n",
    "\n",
    "  df_tmp <- df\n",
    "  df_tmp$target_unit <- target_unit\n",
    "  df_tmp$ target_flow_id <- target_flow_id\n",
    "\n",
    "\n",
    "  # Apply unit conversion\n",
    "  conv_factor <- apply(df_tmp, 1, function(row) {\n",
    "    if (!is.na(row[value_col_id])) {\n",
    "\n",
    "      unit_convert(row[[unit_col_id]], row[['target_unit']], row[['target_flow_id']])\n",
    "    } else {\n",
    "      return(1.0)\n",
    "    }\n",
    "  })\n",
    "\n",
    "  # Update value column with conversion factor\n",
    "  df_tmp[[value_col_id]] <- as.numeric(df_tmp[[value_col_id]]) * conv_factor\n",
    "\n",
    "  # If level is 'reported', update uncertainty column with conversion factor\n",
    "  if (level == 'reported') {\n",
    "    df_tmp[['uncertainty']] <- df_tmp[['uncertainty']] * conv_factor\n",
    "  }\n",
    "\n",
    "  # Update unit column\n",
    "  df_tmp[[unit_col_id]] <- df_tmp[['target_unit']]\n",
    "\n",
    "  # Drop unnecessary columns and return\n",
    "  return(df_tmp[, !names(df_tmp) %in% c('target_unit', 'target_flow_id')])\n",
    "}\n",
    "\n",
    "normalise_values <- function(df) {\n",
    "  #' normalise_values\n",
    "  #'\n",
    "  #' Takes a DataFrame as input, normalizes the 'value' and 'uncertainty'\n",
    "  #' columns by the reference value, and updates the 'reference_value' column accordingly.\n",
    "  #'\n",
    "  #' @param df DataFrame. Dataframe to be normalized.\n",
    "  #'\n",
    "  #' @return DataFrame. Returns a modified DataFrame where the 'value' column has been\n",
    "  #' divided by the 'reference_value' column (or 1.0 if 'reference_value' is null), the 'uncertainty'\n",
    "  #' column has been divided by the 'reference_value' column, and the 'reference_value' column has been\n",
    "  #' replaced with 1.0 if it was not null.\n",
    "  #'\n",
    "  #' @examples\n",
    "  #' # Example usage:\n",
    "  #' normalized_df <- normalize_values(df)\n",
    "  #'\n",
    "  #' @export\n",
    "\n",
    "  # Calculate reference value\n",
    "  reference_value <- sapply(1:nrow(df), function(i) {\n",
    "    if (!is.na(df$reference_value[i])) {\n",
    "      df$reference_value[i]\n",
    "    } else {\n",
    "      1.0\n",
    "    }\n",
    "  })\n",
    "\n",
    "  # Calculate new value, reference value and uncertainty\n",
    "  value_new <- as.numeric(df$value) / reference_value\n",
    "  uncertainty_new <- as.numeric(df$uncertainty) / reference_value\n",
    "  reference_value_new <- sapply(1:nrow(df), function(i) {\n",
    "    if (!is.na(df$reference_value[i])) {\n",
    "      1.0\n",
    "    } else {\n",
    "      NA\n",
    "    }\n",
    "  })\n",
    "\n",
    "  # Assign new values to dataframe and return\n",
    "  df$value <- value_new\n",
    "  df$uncertainty <- uncertainty_new\n",
    "  df$reference_value <- reference_value_new\n",
    "  return(df)\n",
    "}\n",
    "\n",
    "combine_units <- function(numerator, denominator) {\n",
    "  #' Combine fraction of two units into an updated unit string\n",
    "  #'\n",
    "  #' @param numerator Character. Numerator of the fraction.\n",
    "  #' @param denominator Character. Denominator of the fraction.\n",
    "  #'\n",
    "  #' @return Character. Updated unit string after simplification.\n",
    "  #'\n",
    "  #' @examples\n",
    "  #' # Example usage:\n",
    "  #' combine_units(\"m\", \"s\")\n",
    "  #'\n",
    "  #' @export\n",
    "\n",
    "  ret = Simplify(paste0(\"(\", numerator, \")/(\", denominator, \")\"))\n",
    "  # check if ret is numeric, e.g. dimensionless, if not return ret, else return the explicit quotient\n",
    "  if (!grepl(\"^-?\\\\d+\\\\.?\\\\d*$\", ret)) {\n",
    "    return(ret)\n",
    "  } else {\n",
    "    if (grepl('/', denominator)) {\n",
    "      return(paste0(numerator, \"/(\", denominator, \")\"))\n",
    "    } else {\n",
    "      return(paste0(numerator, \"/\", denominator))\n",
    "    }\n",
    "}\n",
    "}\n",
    "\n",
    "\n",
    "#' @title DataSet\n",
    "#'\n",
    "#' @description This class provides methods to store, normalize, select, and aggregate DataSets.\n",
    "#'\n",
    "#' @param parent_variable Character. Variable to collect Data on.\n",
    "#' @param include_databases Optional list[Character] | tuple[Character], optional. Databases to load from.\n",
    "#' @param file_paths Optional list[Character], optional. Paths to load data from.\n",
    "#' @param check_inconsistencies Logical, optional. Whether to check for inconsistencies.\n",
    "#' @param data Optional DataFrame, optional. Specific data to include in the dataset.\n",
    "#'\n",
    "#' @section Attributes:\n",
    "#' \\describe{\n",
    "#'   \\item{data}{DataFrame. The dataset stored in the object.}\n",
    "#' }\n",
    "#'\n",
    "#' @section Methods:\n",
    "#' \\describe{\n",
    "#'   \\item{\\code{normalize()}}{Normalizes the dataset.}\n",
    "#'   \\item{\\code{select()}}{Selects specific data from the dataset.}\n",
    "#'   \\item{\\code{aggregate()}}{Aggregates the dataset.}\n",
    "#' }\n",
    "#'\n",
    "#' @export\n",
    "\n",
    "DataSet <- R6::R6Class(\"DataSet\", inherit=TEBase,\n",
    "  private = list(\n",
    "    # Private attributes\n",
    "    ..df = NULL,\n",
    "    ..columns = NULL,\n",
    "    ..fields = NULL,\n",
    "    ..masks = NULL,\n",
    "\n",
    "    # load TEDFs and compile into NSHASataSet\n",
    "    ..load_files = function(include_databases, file_paths, check_inconsistencies) {\n",
    "        files <- list()\n",
    "\n",
    "        # collect TEDF and append to list\n",
    "        collected_files = collect_files(parent_variable = private$..parent_variable, include_databases = include_databases)\n",
    "\n",
    "        for (i in 1:length(collected_files)) {\n",
    "          file_variable <- collected_files[[i]][[1]]\n",
    "          file_database_id <- collected_files[[i]][[2]]\n",
    "          files <- append(files, TEDF$new(parent_variable = file_variable, database_id = file_database_id ))\n",
    "        }\n",
    "        for (file_path in file_paths) {\n",
    "          files <- apend(files, TEDF$new(parent_variable=private$..parent_variable, file_path=file_path))\n",
    "        }\n",
    "\n",
    "        # raise exception if no TEDF can be loaded\n",
    "        if (length(files) == 0) {\n",
    "          stop(sprintf(\"NO TEDF to load for variabele '%s'.\", private$..parent_variable))\n",
    "        }\n",
    "\n",
    "        # get fields and masks from databases\n",
    "        files_vars = as.vector(unique(sapply(files, function(f) f$parent_variable)))\n",
    "\n",
    "        for (v in files_vars) {\n",
    "          new_fields_comments = read_fields(v)\n",
    "          new_fields = new_fields_comments$fields\n",
    "          new_comments = new_fields_comments$comments\n",
    "          for (col_id in names(c(new_fields, new_comments))) {\n",
    "\n",
    "\n",
    "            if (col_id %in% private$..columns) {\n",
    "              stop(sprintf(\"Cannot load TEDFs due to multiple columns with same ID defined : %s\", col_id))\n",
    "            }\n",
    "\n",
    "          private$..fields <- c(new_fields, private$..fields)\n",
    "          private$..columns <- c(new_fields, private$..columns, new_comments)\n",
    "          private$..masks <- c(private$..masks, read_masks(v))\n",
    "          }\n",
    "        }\n",
    "\n",
    "        # load all TEDFs: load from file, check for inconsistencies (if requested), expand cases and variables\n",
    "        file_dfs <- list()\n",
    "        for (f in files) {\n",
    "          # load\n",
    "          f$load()\n",
    "          #check for inconsistencies\n",
    "          if (check_inconsistencies) {\n",
    "            f$check()\n",
    "          }\n",
    "\n",
    "          # obtain dataframe and insert column parent_variable\n",
    "          df_tmp = f$data\n",
    "          df_tmp <- df_tmp <- cbind(parent_variable = f$parent_variable, df_tmp)\n",
    "\n",
    "          # append to dataframe list\n",
    "          file_dfs <- append(file_dfs, df_tmp)\n",
    "        }\n",
    "\n",
    "        # compile dataset from the dataframes loaded from the individual files\n",
    "        data <- do.call(cbind, file_dfs)\n",
    "\n",
    "        # Query relevant variables\n",
    "        data <- as.data.frame(data) %>% filter(parent_variable == private$..parent_variable)\n",
    "\n",
    "        # Drop entries with unknown variables and warn\n",
    "        for (var_type in c('variable', 'reference_variable')) {\n",
    "          cond <- (!is.na(data[[var_type]]) & (data[[var_type]] != \"\") &\n",
    "            apply(data, 1, function(row) {\n",
    "              !paste(row[[\"parent_variable\"]], row[[var_type]], sep = \"|\") %in% names(private$..var_specs)\n",
    "            }))\n",
    "\n",
    "          if (any(cond)) {\n",
    "            warning(paste(\"Unknown\", var_type, \"so dropping rows:\\n\", data[cond, var_type]))\n",
    "            data <- data[!cond, ]\n",
    "          }\n",
    "        }\n",
    "\n",
    "        # return\n",
    "        return(as.data.frame(data))\n",
    "    },\n",
    "\n",
    "    ..normalise = function(override) {\n",
    "      if (is.null(override)) {\n",
    "        override <- list()\n",
    "      }\n",
    "\n",
    "      # get overridden var specs\n",
    "      var_flow_ids <- lapply(names(private$..var_specs), function(var_name) {\n",
    "        var_specs <- private$..var_specs[[var_name]]\n",
    "        if ('flow_id'%in% names(var_specs)) {\n",
    "          return(var_specs[['flow_id']])\n",
    "        } else {\n",
    "          return(NULL)\n",
    "        }\n",
    "      })\n",
    "      names(var_flow_ids) <- names(private$..var_specs)\n",
    "      var_flow_ids <- var_flow_ids[order(names(var_flow_ids))]\n",
    "\n",
    "      var_units <- lapply(names(private$..var_specs), function(var_name) {\n",
    "        var_specs <- private$..var_specs[[var_name]]\n",
    "          return(var_specs[['default_unit']])\n",
    "\n",
    "      })\n",
    "      names(var_units) <- names(private$..var_specs)\n",
    "      var_units <- Filter(function(x) !is.null(x), var_units)\n",
    "\n",
    "      # Get the names common to both var_units and override\n",
    "      common_names <- intersect(names(var_units), names(override))\n",
    "\n",
    "      # Replace values in var_units with values from override for common names\n",
    "      var_units[common_names] <- override[common_names]\n",
    "      var_units <- var_units[order(names(var_units))]\n",
    "\n",
    "      # normalise reference units, normalise reference values, and normalise reported units\n",
    "      normalised <- private$..df %>%\n",
    "              normalise_units(level = 'reference', var_units = var_units, var_flow_ids = var_flow_ids) %>%\n",
    "              normalise_values() %>%\n",
    "              normalise_units(level = 'reported', var_units = var_units, var_flow_ids = var_flow_ids)\n",
    "\n",
    "      # return normalised data and variable units\n",
    "      return(list(normalised=normalised, var_units=var_units))\n",
    "    },\n",
    "\n",
    "\n",
    "    ..select = function(override, drop_singular_fields, extrapolate_period, ...) {\n",
    "      field_vals_select <- list(...)\n",
    "\n",
    "      # start from normalised data\n",
    "      normalised_units <- private$..normalise(override)\n",
    "      selected <- normalised_units$normalised\n",
    "      var_units <- normalised_units$var_units\n",
    "\n",
    "      # drop unit columns and reference falue column\n",
    "      selected <- selected %>% select( -unit, -reference_unit, -reference_value)\n",
    "\n",
    "      # drop columns containing comments and uncertaindty field (which is currently unsupported)\n",
    "      comment_columns <- Filter(function(col_id) {(private$..columns[[col_id]]$col_type == \"comment\")}, names(private$..columns))\n",
    "      selected <- selected %>%\n",
    "        select(-uncertainty,  -any_of(comment_columns))\n",
    "\n",
    "      reference_variable_temp <- selected$reference_variable\n",
    "\n",
    "      # add parent variable as prefix to other variable columns\n",
    "      selected <- mutate(selected, variable = paste(parent_variable, variable, sep = \"|\"))\n",
    "      selected <- mutate(selected, reference_variable = ifelse((is.na(reference_variable_temp) | (reference_variable_temp ==\"\")), NA, paste(parent_variable, reference_variable_temp, sep = \"|\")))\n",
    "      selected <- select(selected, -parent_variable)\n",
    "\n",
    "      # raise exception if fields listed in arguments that are uknown\n",
    "      for (field_id in names(field_vals_select)) {\n",
    "\n",
    "        if (!(field_id %in% names(private$..fields))) {\n",
    "          stop(paste(\"Field '\", field_id, \"' does not exist and cannot be used for selection.\", sep = \"\"))\n",
    "        }\n",
    "      }\n",
    "\n",
    "      # order fields for selection: period must be expanded last due to the interpolation\n",
    "      fields_select <- list()\n",
    "      for (col_id in names(field_vals_select)) {\n",
    "        fields_select[[col_id]] <- private$..fields[[col_id]]\n",
    "      }\n",
    "\n",
    "      for (col_id in names(private$..fields)) {\n",
    "        if (!(col_id %in% c('period', field_vals_select))) {\n",
    "          fields_select[[col_id]] <- private$..fields[[col_id]]\n",
    "        }\n",
    "      }\n",
    "      fields_select[['period']] <- private$..fields[['period']]\n",
    "\n",
    "      # select and expand fields\n",
    "      for (col_id in names(fields_select)) {\n",
    "        field <- fields_select[[col_id]]\n",
    "        field_vals <- if (col_id %in% names(field_vals_select)) { field_vals_select[[col_id]]} else {NULL}\n",
    "        selected <- field$select_and_expand(selected, col_id, field_vals, extrapolate_period=extrapolate_period)\n",
    "      }\n",
    "\n",
    "      # drop custom fields with only one value if specified in method argument\n",
    "      df_cols <- sapply(names(private$..fields), function(col_id) {\n",
    "          field <- private$..fields[[col_id]]\n",
    "\n",
    "          if (inherits(field, \"CustomFieldDefinition\")) {\n",
    "            return(col_id)\n",
    "          } else {\n",
    "            return(NULL)\n",
    "          }\n",
    "        })\n",
    "      if (drop_singular_fields) {\n",
    "        columns_to_drop <- c(\n",
    "          sapply(names(private$..fields), function(col_id) {\n",
    "            field <- private$..fields[[col_id]]\n",
    "            if (inherits(field, \"CustomFieldDefinition\") && n_distinct(selected[[col_id]]) < 2) {\n",
    "              return(col_id)\n",
    "            } else {\n",
    "              return(NULL)\n",
    "            }\n",
    "          })\n",
    "        )\n",
    "        names(columns_to_drop )<- NULL\n",
    "        columns_to_drop <- unlist(unique( Filter(Negate(is.null), columns_to_drop)))\n",
    "        selected <- selected %>%\n",
    "        select(-any_of(columns_to_drop))\n",
    "\n",
    "      }\n",
    "      # apply mappings\n",
    "      selected <- private$..apply_mappings(selected, var_units)\n",
    "\n",
    "      # drop rows with failed mappings\n",
    "      selected <- selected[!is.na(selected$value), , drop = FALSE]\n",
    "\n",
    "      # get map of variable references\n",
    "      var_references <- selected %>%\n",
    "                  select(variable, reference_variable) %>%\n",
    "                  distinct() %>%\n",
    "                  mutate(variable = as.character(variable)) %>%\n",
    "                  distinct()\n",
    "\n",
    "      # Check for multiple reference variables per reported variable\n",
    "      if (duplicated(list(var_references$variable))) {\n",
    "        stop(\"Multiple reference variables per reported variable found\")\n",
    "      }\n",
    "      var_references <- setNames(var_references$reference_variable, var_references$variable)\n",
    "\n",
    "      # Remove 'reference_variable' column\n",
    "      selected <- selected %>%\n",
    "                    select(-reference_variable)\n",
    "      selected <- selected[order(selected$source),]\n",
    "\n",
    "      # strip off unit variants\n",
    "      var_units <- lapply(var_units, function(unit) {\n",
    "        unlist(strsplit(unit, \";\"))[1]\n",
    "      })\n",
    "\n",
    "      # return\n",
    "      selected_var_units_and_references <- list(selected=selected, var_units=var_units, var_references=var_references)\n",
    "      return(selected_var_units_and_references)\n",
    "    },\n",
    "\n",
    "    # apply mappings between entry types\n",
    "    ..apply_mappings = function(expanded, var_units) {\n",
    "\n",
    "      #list of columns to group by\n",
    "      group_cols <- setdiff(names(expanded), c('variable', 'reference_variable', 'value'))\n",
    "\n",
    "      # Perform group_by and do not drop NA values\n",
    "      grouped <- expanded %>% group_split(across(all_of(group_cols)), .drop = FALSE)\n",
    "\n",
    "      # Create return list\n",
    "      ret <- list()\n",
    "\n",
    "      # loop over groups\n",
    "      for (i in seq_along(grouped)) {\n",
    "        # get rows in group\n",
    "        rows <- grouped[[i]]\n",
    "\n",
    "        # 1. convert FLH to OCF\n",
    "        cond <- endsWith(rows$variable, '|FLH')\n",
    "        if (any(cond)) {\n",
    "\n",
    "          # Multiply 'value' by conversion factor\n",
    "          rows$value[cond] <- rows$value[cond] * apply(rows[cond,], 1, function(row) {\n",
    "            return(unit_convert(var_units[[row[['variable']]]], 'a'))})\n",
    "\n",
    "          # Replace '|FLH' with '|OCF' in 'variable'\n",
    "          rows$variable[cond] <- gsub(\"|FLH\", \"|OCF\", rows$variable[cond], fixed = TRUE)\n",
    "        }\n",
    "\n",
    "          # 2. convert OPEX Fixed Relative to OPEX Fixed\n",
    "          cond <- endsWith(rows$variable, '|OPEX Fixed Relative')\n",
    "          if (any(cond)) {\n",
    "          # Define a function to calculate the conversion factor\n",
    "          calculate_conversion <- function(row) {\n",
    "            variable <- gsub(\"|OPEX Fixed Relative\", \"|CAPEX\", row[['variable']], fixed = TRUE)\n",
    "            var_units_reference <- var_units[[gsub(\"|OPEX Fixed Relative\", \"|OPEX Fixed\", row[['variable']], fixed = TRUE)]]\n",
    "            var_units_dividend <- paste(var_units[[variable]], '/a', sep = \"\")\n",
    "            filter_condition <- rows$variable == variable\n",
    "            var_units_df <-  filter(rows,  filter_condition)\n",
    "\n",
    "            return(unit_convert(var_units[row['variable']], 'dimensionless') *\n",
    "                    unit_convert(var_units_dividend,var_units_reference) *\n",
    "                    var_units_df$value[1])\n",
    "          }\n",
    "\n",
    "          # Calculate the conversion factor and update 'value' for rows satisfying the condition\n",
    "          rows$value[cond] <- rows$value[cond] * apply( rows[cond,], 1, calculate_conversion)\n",
    "          # Replace '|OPEX Fixed Relative' with '|OPEX Fixed' in 'variable'\n",
    "          rows$variable[cond] <- gsub(\"|OPEX Fixed Relative\", \"|OPEX Fixed\", rows$variable[cond], fixed = TRUE)\n",
    "\n",
    "          # Assign 'reference_variable' based on modified 'variable'\n",
    "          rows$reference_variable[cond] <- apply(rows[cond,],1, function(row) {\n",
    "            var_units_variable <- gsub(\"|OPEX Fixed\", \"|CAPEX\", row[['variable']], fixed = TRUE)\n",
    "            filter_condition <- rows$variable == var_units_variable\n",
    "            var_units_df <-  filter(rows,  filter_condition)\n",
    "            if (nrow(var_units_df) > 0) {\n",
    "              return(var_units_df$reference_variable[1])\n",
    "            } else {\n",
    "              return(NA)\n",
    "            }\n",
    "          })\n",
    "\n",
    "          # Check if there are rows with null 'value' after the operation\n",
    "          if (any(cond & is.na(rows$value))) {\n",
    "            warning(\"No CAPEX value matching an OPEX Fixed Relative value found.\")\n",
    "          }\n",
    "        }\n",
    "\n",
    "        # 3. convert OPEX Fixed Specific to OPEX Fixed\n",
    "        cond <- endsWith(rows$variable, \"|OPEX Fixed Specific\")\n",
    "        if (any(cond)) {\n",
    "\n",
    "          # Define a function to calculate the conversion factor\n",
    "          calculate_conversion <- function(row) {\n",
    "            unit_conversion_1_from <- paste(var_units[[row[['variable']]]], '/a', sep = \"\")\n",
    "            unit_conversion_1_to<- gsub(\"|OPEX Fixed Specific\", \"|OPEX Fixed\", row[['variable']], fixed = TRUE)\n",
    "\n",
    "            unit_conversion_2_from <- paste(var_units[[row['reference_variable']]], '/a', sep = \"\")\n",
    "            unit_conversion_2_to <- var_units[[gsub(\"(Input|Output)\", \"\\\\1 Capacity\", row['reference_variable'], perl=TRUE)]]\n",
    "            unit_conversion_2_flow_type <- if ('flow_id' %in% private$..var_specs[[row['reference_variable']]]) {\n",
    "              private$..var_specs[[row['reference_variable']]]$flow_id\n",
    "            } else {\n",
    "              NaN\n",
    "            }\n",
    "            unit_conversion_3_from <- var_units[[gsub(\"|OPEX Fixed Specific\", '|OCF'), row[['variable']], fixed=TRUE]]\n",
    "            unit_conversion_3_to <- 'dimensionless'\n",
    "\n",
    "            var_units_df <- subset(rows, variable == gsub(\"|OPEX Fixed Specific\", \"|OCF\", row['variable'], fixed = TRUE))\n",
    "\n",
    "            if (nrow(var_units_df) > 0) {\n",
    "              return(unit_convert(unit_conversion_1_from, unit_conversion_1_to) /\n",
    "                    unit_convert(unit_conversion_2_from, unit_conversion_2_to, unit_conversion_2_flow_type) *\n",
    "                    unit_convert(unit_conversion_3_from, unit_conversion_4_to) *\n",
    "                    var_units_df$value[1])\n",
    "            } else {\n",
    "              return(NA)\n",
    "            }\n",
    "          }\n",
    "\n",
    "          # Calculate the conversion factor and update 'value' for rows satisfying the condition\n",
    "          rows$value[cond] <- rows$value[cond] * apply(rows[cond,],1,calculate_conversion)\n",
    "\n",
    "          # Replace '|OPEX Fixed Specific' with '|OPEX Fixed' in 'variable'\n",
    "          rows$variable[cond] <- gsub(\"|OPEX Fixed Specific\", \"|OPEX Fixed\", rows$variable[cond], fixed = TRUE)\n",
    "\n",
    "          # Update 'reference_variable' by replacing 'Input' or 'Output' with 'Input Capacity' or 'Output Capacity'\n",
    "          rows$reference_variable[cond] <- gsub('(Input|Output)', '\\\\1 Capacity', rows$reference_variable[cond], perl = TRUE)\n",
    "\n",
    "          # Check if there are rows with null 'value' after the operation\n",
    "          if (any(cond & is.na(rows$value))) {\n",
    "            warning(\"No OCF value matching an OPEX Fixed Specific value found.\")\n",
    "          }\n",
    "        }\n",
    "\n",
    "        # 4. convert efficiencies (Output over Input) to demands (Input over Output)\n",
    "        cond1 <- grepl(\"\\\\|Output(?: Capacity)?\\\\|\", rows$variable)\n",
    "        if (any(!is.na(rows$reference_variable))) {\n",
    "          cond2 <- grepl(\"\\\\|Input(?: Capacity)?\\\\|\", rows$reference_variable)\n",
    "                        } else {\n",
    "          cond2 <- FALSE}\n",
    "        cond <- cond1 & cond2\n",
    "\n",
    "        if (any(cond)) {\n",
    "          rows$value[cond] <- 1.0 / rows$value[cond]\n",
    "          rows$variable_new <- NaN\n",
    "          rows$variable_new[cond] <- rows$reference_variable[cond]\n",
    "          rows$reference_variable[cond] <- rows$variable[cond]\n",
    "          rows$variable[cond] <- rows$variable_new[cond]\n",
    "          rows <- rows[!names(rows) %in% c(\"variable_new\")]\n",
    "        }\n",
    "\n",
    "        # 5. convert all references to primary output\n",
    "        if (any(!is.na(rows$reference_variable))) {\n",
    "          cond1 <- (grepl(\"\\\\|Output(?: Capacity)?\\\\|\", rows$reference_variable) | grepl(\"\\\\|Input(?: Capacity)?\\\\|\", rows$reference_variable))\n",
    "        } else {\n",
    "          cond1 <- FALSE\n",
    "        }\n",
    "        cond2 <- unlist(lapply(rows$variable, function(var) {\n",
    "          'default_reference' %in% names(private$..var_specs[[var]])\n",
    "          }))\n",
    "\n",
    "        # define helper function for cond3\n",
    "        get_default_reference <- function(var) {\n",
    "          if ('default_reference' %in% names(self$var_specs[[var]])) {\n",
    "            return(self$var_specs[[var]]$default_reference)\n",
    "          } else {\n",
    "            return(NA)\n",
    "          }\n",
    "        }\n",
    "        cond3  <- lapply(rows$variable, get_default_reference) != rows[['reference_variable']]\n",
    "\n",
    "        cond <- cond1 & cond2 & cond3\n",
    "        if (any(cond)) {\n",
    "          regex_find <- \"\\\\|(Input|Output)(?: Capacity)?\\\\|\"\n",
    "          regex_repl <- \"|\\\\1|\"\n",
    "          rows$reference_variable_new <- NaN\n",
    "          rows$reference_variable_new[cond] <- sapply(rows$variable[cond], function(var) {\n",
    "\n",
    "            private$..var_specs[[var]]$default_reference\n",
    "          })\n",
    "          calculate_conversion <- function(row) {\n",
    "            reference_variable_new <- gsub(regex_find, regex_repl, row['reference_variable_new'][[1]])\n",
    "            if(grepl(\"Capacity\", row['reference_variable'][[1]])) {\n",
    "              if (grepl( \"/a\", var_units[[row['reference_variable_new'][[1]]]])) {\n",
    "                row_reference_variable_new <- sub(\"/a\", \"\", var_units[[row['reference_variable_new'][[1]]]])\n",
    "              } else {\n",
    "                row_reference_variable_new <- paste0(\"a*\", var_units[[row['reference_variable_new'][[1]]]])\n",
    "\n",
    "              }\n",
    "            } else {\n",
    "              row_reference_variable_new <- var_units[[row['reference_variable'][[1]]]]\n",
    "            }\n",
    "\n",
    "            var_units_reference_variable_new <- var_units[[reference_variable_new]]\n",
    "            tail_reference_variable_new <-  tail(strsplit(row['reference_variable_new'][1], \"\\\\|\")[[1]], 1)\n",
    "\n",
    "            reference_variable <- gsub(regex_find, regex_repl, row['reference_variable'][[1]] )\n",
    "            if(grepl(\"Capacity\", row['reference_variable'][[1]])) {\n",
    "              if (grepl( \"/a\",var_units[[row['reference_variable'][[1]]]])) {\n",
    "                row_reference_variable <- sub(\"/a\", \"\", var_units[[row['reference_variable'][[1]]]])\n",
    "              } else {\n",
    "                row_reference_variable<- paste0(\"a*\", var_units[[row['reference_variable'][[1]]]])\n",
    "\n",
    "              }\n",
    "            } else {\n",
    "              row_reference_variable <- var_units[[row['reference_variable'][[1]]]]\n",
    "            }\n",
    "\n",
    "            var_units_reference_variable <- var_units[[reference_variable]]\n",
    "            tail_reference_variable <-  tail(strsplit(row['reference_variable'][1], \"\\\\|\")[[1]], 1)\n",
    "\n",
    "            rows_cond1 <-  rows$variable == reference_variable\n",
    "            rows_cond2 <-  rows$reference_variable == reference_variable_new\n",
    "            var_units_df <-  filter(rows, rows_cond2 & rows_cond2)\n",
    "\n",
    "            return(unit_convert(row_reference_variable_new, var_units_reference_variable_new, tail_reference_variable_new) /\n",
    "                        unit_convert(row_reference_variable, var_units_reference_variable, tail_reference_variable) *\n",
    "                            var_units_df$value[1])\n",
    "\n",
    "            }\n",
    "          # Calculate the conversion factor and update 'value' for rows satisfying the condition\n",
    "          rows$value[cond] <- rows$value[cond] * apply( rows[cond,], 1, calculate_conversion)\n",
    "\n",
    "          rows$reference_variable[cond] <- rows$reference_variable_new[cond]\n",
    "          rows <- rows[!names(rows) %in% c(\"reference_variable_new\")]\n",
    "          if (any(cond & is.na(rows$value))) {\n",
    "            warning(paste(\"No appropriate mapping found to convert row reference to primary output:\",\n",
    "                          rows[cond & is.na(rows$value), ]))\n",
    "\n",
    "          }\n",
    "        }\n",
    "\n",
    "        # add to return list\n",
    "        ret <- append(ret, list(rows))\n",
    "      }\n",
    "      # convert return list to dataframe and return\n",
    "      return(bind_rows(ret))\n",
    "    },\n",
    "\n",
    "  # clean up: sort columns and rows, round values, insert units\n",
    "  ..cleanup = function(df, var_units) {\n",
    "      # Sort columns and rows\n",
    "      df_cols <- sapply(names(private$..fields), function(col_id) {\n",
    "          field <- private$..fields[[col_id]]\n",
    "\n",
    "          if (inherits(field, \"CustomFieldDefinition\")) {\n",
    "            return(col_id)\n",
    "          } else {\n",
    "            return(NULL)\n",
    "          }\n",
    "        })\n",
    "      names(df_cols) <- NULL\n",
    "      cols_sorted <- unlist(unique(c(df_cols, 'source', 'variable', 'reference_variable', 'region', 'period', 'value')))\n",
    "      cols_sorted <- cols_sorted[cols_sorted %in% names(df)]\n",
    "      df <- select(df, any_of(cols_sorted))\n",
    "      cols_sorted <- cols_sorted[-which(cols_sorted == \"value\")]\n",
    "      df <- df[do.call(order, df[cols_sorted]), ]\n",
    "\n",
    "      # Round values\n",
    "      df$value <- ifelse(is.na(df$value), df$value, signif(df$value, digits = 4))\n",
    "\n",
    "      # Insert column containing units\n",
    "      df <- as.data.frame(append(df, list(unit=NaN), after = match(\"value\", names(df))-1))\n",
    "      if (\"reference_variable\" %in% colnames(df)) {\n",
    "        df$unit <- apply(df, 1, function(row) {\n",
    "          if (!is.na(row[\"reference_variable\"])) {\n",
    "            combine_units(var_units[[row[\"variable\"]]], var_units[[row[\"reference_variable\"]]])\n",
    "          } else {\n",
    "            var_units[row[\"variable\"]]\n",
    "          }\n",
    "        })\n",
    "      } else {\n",
    "        df$unit <- var_units[df$variable]\n",
    "      }\n",
    "      return(df)\n",
    "    }\n",
    "\n",
    "  ),\n",
    "\n",
    "  public = list(\n",
    "\n",
    "    #' initialise\n",
    "    #'\n",
    "    #' Initialise parent class and fields, load data from specified databases and files'''\n",
    "    initialize = function(parent_variable,\n",
    "                           include_databases = NULL,\n",
    "                           file_paths = NULL,\n",
    "                           check_inconsistencies = FALSE,\n",
    "                           data = NULL) {\n",
    "      super$initialize(parent_variable)\n",
    "\n",
    "      # initialise fields\n",
    "      private$..df <- NULL\n",
    "      private$..columns <- base_columns\n",
    "      private$..fields <- lapply(private$..columns, function(field) {\n",
    "        if (inherits(field, \"AbstractFieldDefinition\")) field else NULL\n",
    "      })\n",
    "      private$..fields <- Filter(Negate(is.null), private$..fields)\n",
    "      private$..masks <- list()\n",
    "\n",
    "      # Load data if provided, otherwise load from TEDataFiles\n",
    "      if (!is.null(data)) {\n",
    "        private$..df <- data.frame(data)\n",
    "      } else {\n",
    "        # read TEDataFiles and combine into dataset\n",
    "        if (!is.null(include_databases)) {\n",
    "            include_databases <- list(include_databases)\n",
    "        } else {\n",
    "            include_databases <- list(names(databases))\n",
    "        }\n",
    "\n",
    "        # in no file paths are given, set to empty list\n",
    "        if (is.null(file_paths)){\n",
    "            file_paths <- list()\n",
    "        }\n",
    "        private$..df <- data.frame(private$..load_files(include_databases, file_paths, check_inconsistencies))\n",
    "      }\n",
    "    },\n",
    "\n",
    "    #' @description Normalize data: default reference units, reference value equal to 1.0, default reported units\n",
    "    #'\n",
    "    #' @param override Optional list[Character]. Dictionary with key, value pairs of variables to override.\n",
    "    #' @param inplace Logical, optional. Whether to do the normalization in place.\n",
    "    #'\n",
    "    #' @return DataFrame. If \\code{inplace} is \\code{FALSE}, returns normalized dataframe.\n",
    "    #'\n",
    "    #' @examples\n",
    "    #' # Example usage:\n",
    "    #' dataset$normalize(override = list(\"variable1\" = \"value1\"), inplace = FALSE)\n",
    "    #'\n",
    "    #' @export\n",
    "    normalise = function(override = NULL, inplace = FALSE) {\n",
    "      normalised <- private$..normalise(override)\n",
    "      if (inplace) {\n",
    "        private$..df <- data.frame(normalised$normalised)\n",
    "      } else {\n",
    "        return(data.frame(normalised$normalised))\n",
    "      }\n",
    "    },\n",
    "\n",
    "    #' @description Select desired data from the dataframe\n",
    "    #'\n",
    "    #' @param override Optional list[Character]. Dictionary with key, value pairs of variables to override.\n",
    "    #' @param drop_singular_fields Logical, optional. If \\code{TRUE}, drop custom fields with only one value.\n",
    "    #' @param extrapolate_period Logical, optional. If \\code{TRUE}, extrapolate values if no value for this period is given.\n",
    "    #' @param ... IDs of values to select.\n",
    "    #'\n",
    "    #' @return DataFrame. DataFrame with selected values.\n",
    "    #'\n",
    "    #' @examples\n",
    "    #' # Example usage:\n",
    "    #' dataset$select(override = list(\"variable1\" = \"value1\"), drop_singular_fields = TRUE, extrapolate_period = FALSE, field1 = \"value1\")\n",
    "    #'\n",
    "    #' @export\n",
    "    select = function(override = NULL,\n",
    "                      drop_singular_fields = TRUE,\n",
    "                      extrapolate_period = TRUE,\n",
    "                      ...) {\n",
    "      selected_var_units_and_references <- private$..select(override, drop_singular_fields, extrapolate_period, ...)\n",
    "      selected <- selected_var_units_and_references$selected\n",
    "      var_units <- selected_var_units_and_references$var_units\n",
    "      var_references <- selected_var_units_and_references$var_references\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # Inserting a new column 'reference_variable' at a specific position in the data frame\n",
    "\n",
    "      selected <- as.data.frame(append(selected, list(reference_variable=NA), after=match(\"variable\", names(selected))-1))\n",
    "\n",
    "\n",
    "      # Mapping values from 'var_references' to the 'reference_variable' column based on 'variable'\n",
    "      selected$reference_variable <- var_references[selected$variable]\n",
    "\n",
    "      result <- private$..cleanup(selected, var_units)\n",
    "      return(result)\n",
    "    },\n",
    "\n",
    "    #' @description Aggregates data based on specified parameters, applies masks,\n",
    "    #' and cleans up the resulting DataFrame.\n",
    "    #'\n",
    "    #' @param override Optional list[Character]. Dictionary with key, value pairs of variables to override.\n",
    "    #' @param drop_singular_fields Logical, optional. If \\code{TRUE}, drop custom fields with only one value.\n",
    "    #' @param extrapolate_period Logical, optional. If \\code{TRUE}, extrapolate values if no value for this period is given.\n",
    "    #' @param agg Optional Character | list[Character] | tuple[Character]. Specifies which fields to aggregate over.\n",
    "    #' @param masks Optional list[Mask]. Specifies a list of Mask objects that will be applied to the data during aggregation. These masks can be used to filter or weight the data based on certain conditions defined in the Mask objects.\n",
    "    #' @param masks_database Logical, optional. Determines whether to include masks from databases in the aggregation process. If \\code{TRUE}, masks from databases will be included along with any masks provided as function arguments. If \\code{FALSE}, only the masks provided as function arguments will be applied.\n",
    "    #'\n",
    "    #' @return DataFrame. The \\code{aggregate} method returns a pandas DataFrame that has been cleaned up and aggregated based on the specified parameters and input data. The method performs aggregation over component fields and case fields, applies weights based on masks, drops rows with NaN weights, aggregates with weights, inserts reference variables, sorts columns and rows, rounds values, and inserts units before returning the final cleaned and aggregated DataFrame.\n",
    "    #'\n",
    "    #' @examples\n",
    "    #' # Example usage:\n",
    "    #' dataset$aggregate(override = list(\"variable1\" = \"value1\"), drop_singular_fields = TRUE, extrapolate_period = FALSE, agg = \"field\", masks = list(mask1, mask2), masks_database = TRUE)\n",
    "    #'\n",
    "    #' @export\n",
    "    aggregate = function(override=NULL,\n",
    "            drop_singular_fields=TRUE,\n",
    "            extrapolate_period=TRUE,\n",
    "            agg=NULL,\n",
    "            masks=NULL,\n",
    "            masks_database=TRUE,\n",
    "            ... ) {\n",
    "      # get selection\n",
    "      selected_var_units_and_references <- private$..select(override, extrapolate_period, drop_singular_fields, ...)\n",
    "      selected <- selected_var_units_and_references[[1]]\n",
    "      var_units <- selected_var_units_and_references[[2]]\n",
    "      var_references <- selected_var_units_and_references[[3]]\n",
    "\n",
    "      # compile masks from databases and function argument into one list\n",
    "      if (!is.null(masks) && any(!sapply(masks, function(m) inherits(m, \"Mask\")))) {\n",
    "        stop(\"Function argument 'masks' must contain a list of posted.masking.Mask objects.\")\n",
    "      }\n",
    "      masks <- c(if (masks_database) {private$..masks} else {list()}, if(!is.null(masks)) {masks} else {list()} )\n",
    "\n",
    "      # aggregation\n",
    "      component_fields <- names(Filter(function(field) field$field_type == 'component', private$..fields))\n",
    "      if (is.null(agg)) {\n",
    "        agg <- c(component_fields, 'source')\n",
    "      } else {\n",
    "        if (!is.list(agg)) {\n",
    "          agg <- list(agg)\n",
    "        }\n",
    "        for (a in agg) {\n",
    "          if (!is.character(a)) {\n",
    "            stop(sprintf(\"Field ID in argument 'agg' must be a string but found: %s\", a))\n",
    "          }\n",
    "          if (!any(a %in% names(private$..fields))) {\n",
    "            stop(sprintf(\"Field ID in argument 'agg' is not a valid field: %s\", a))\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "\n",
    "      # aggregate over component fields\n",
    "      group_cols <- subset(names(selected), !(names(selected) == 'value' | (names(selected) %in% agg & names(selected) %in% component_fields)))\n",
    "      aggregated <- selected %>%\n",
    "          group_by_at(vars(group_cols)) %>%\n",
    "          summarise(value = sum(value), .groups = 'drop') %>%\n",
    "          ungroup()\n",
    "\n",
    "      # aggregate over cases fields\n",
    "      group_cols <- subset(names(selected), !(names(selected) == 'value' | (names(selected) %in% agg)))\n",
    "      grouped <- aggregated %>% group_split(across(all_of(group_cols)), .drop = FALSE)\n",
    "\n",
    "      ret <- list()\n",
    "      for (i in seq_along(grouped)) {\n",
    "        rows <- grouped[[i]]\n",
    "        # set default weights to 1.0\n",
    "        rows$weight <- 1.0\n",
    "\n",
    "        # update weights by applying masks\n",
    "        for (mask in masks) {\n",
    "          if (mask$matches(rows)) {\n",
    "            rows$weight <- rows$weight * mask$get_weights(rows)\n",
    "          }\n",
    "        }\n",
    "\n",
    "        # Drop all rows with missing values in the 'weight' column\n",
    "        rows <- rows[!is.na(rows$weight), , drop = FALSE]\n",
    "\n",
    "        if (!is_empty(rows)) {\n",
    "          # Aggregate with weighted average\n",
    "          out <- rows %>%\n",
    "            group_by_at(vars(group_cols)) %>%\n",
    "            summarise(value = weighted.mean(value, w = weight), .groups ='drop') %>%\n",
    "            ungroup()\n",
    "          # Add to return list\n",
    "\n",
    "          ret <- append(ret, list(out))\n",
    "        }\n",
    "      }\n",
    "      aggregated <- bind_rows(ret)\n",
    "\n",
    "      # insert reference variable\n",
    "      unique_vars <- unique(aggregated$variable)\n",
    "\n",
    "      # Filter out NULL and NA values and extract corresponding var_references\n",
    "      var_ref_unique <- unique(lapply(unique_vars, function(var) ifelse(!is.null(var_references[var]), var_references[var], NULL)))\n",
    "      var_ref_unique <- Filter(function(x) !is.null(x) & !is.na(x), var_ref_unique)\n",
    "\n",
    "      agg_append <- list()\n",
    "      for (ref_var in var_ref_unique) {\n",
    "        df <- data.frame(variable = ref_var, value = 1.0)\n",
    "        col_ids <- names(private$..fields)[names(private$..fields) %in% names(aggregated)]\n",
    "        col_ids <- setdiff(col_ids, names(df))\n",
    "        for (col_id in col_ids) {\n",
    "          df[col_id] <- '*'\n",
    "        }\n",
    "        agg_append <- append(agg_append, list(df))\n",
    "      }\n",
    "\n",
    "      if (length(agg_append) > 0) {\n",
    "        agg_append <- bind_rows(agg_append)\n",
    "        agg_append <- agg_append[order(rownames(agg_append)), ]  # Sort rows\n",
    "        for (col_id in names(private$..fields)) {\n",
    "          field <- private$..fields[[col_id]]\n",
    "          if (!(col_id %in% names(aggregated))) {\n",
    "            next\n",
    "          }\n",
    "          unique_values <- unique(aggregated[[col_id]])\n",
    "          agg_append <- field$select_and_expand(agg_append,col_id, as.list(unique(aggregated[[col_id]])))\n",
    "        }\n",
    "      } else {\n",
    "        agg_append <- NULL\n",
    "      }\n",
    "    # convert return list to dataframe, reset index and clean up\n",
    "    return(private$..cleanup(bind_rows(list(aggregated, agg_append)), var_units))\n",
    "\n",
    "    }\n",
    "     ),\n",
    "  active = list(\n",
    "    # access dataframe\n",
    "    data = function(df) {\n",
    "      if (missing(df)) return(private$..df)\n",
    "      else private$..df <- df\n",
    "    }\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "print(\"finished loading\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 12 x 15</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>parent_variable</th><th scope=col>subtech</th><th scope=col>size</th><th scope=col>region</th><th scope=col>period</th><th scope=col>variable</th><th scope=col>reference_variable</th><th scope=col>value</th><th scope=col>uncertainty</th><th scope=col>unit</th><th scope=col>reference_value</th><th scope=col>reference_unit</th><th scope=col>comment</th><th scope=col>source</th><th scope=col>source_detail</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2020</td><td>CAPEX          </td><td>Input Capacity|Electricity</td><td>45.40385963</td><td>0.000000</td><td>USD_2005  </td><td>1</td><td>MWh/a</td><td>                                                                          </td><td>Vartiainen22</td><td>Page 4, Figure 4</td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2030</td><td>CAPEX          </td><td>Input Capacity|Electricity</td><td>27.24231578</td><td>5.675482</td><td>USD_2005  </td><td>1</td><td>MWh/a</td><td>                                                                          </td><td>Vartiainen22</td><td>Page 4, Figure 4</td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2040</td><td>CAPEX          </td><td>Input Capacity|Electricity</td><td>15.89135087</td><td>8.513224</td><td>USD_2005  </td><td>1</td><td>MWh/a</td><td>                                                                          </td><td>Vartiainen22</td><td>Page 4, Figure 4</td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2050</td><td>CAPEX          </td><td>Input Capacity|Electricity</td><td> 9.08077193</td><td>8.513224</td><td>USD_2005  </td><td>1</td><td>MWh/a</td><td>                                                                          </td><td>Vartiainen22</td><td>Page 4, Figure 4</td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2020</td><td>OPEX Fixed     </td><td>Input Capacity|Electricity</td><td> 0.68105789</td><td>      NA</td><td>USD_2005/a</td><td>1</td><td>MWh/a</td><td>1.5% of CAPEX; reported in units of electric capacity                     </td><td>Vartiainen22</td><td>Page 4          </td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2030</td><td>OPEX Fixed     </td><td>Input Capacity|Electricity</td><td> 0.23837026</td><td>      NA</td><td>USD_2005/a</td><td>1</td><td>MWh/a</td><td>10% LR decrease                                                           </td><td>Vartiainen22</td><td>Page 4          </td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2040</td><td>OPEX Fixed     </td><td>Input Capacity|Electricity</td><td> 0.08286204</td><td>      NA</td><td>USD_2005/a</td><td>1</td><td>MWh/a</td><td>10% LR decrease                                                           </td><td>Vartiainen22</td><td>Page 4          </td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2050</td><td>OPEX Fixed     </td><td>Input Capacity|Electricity</td><td> 0.02837741</td><td>      NA</td><td>USD_2005/a</td><td>1</td><td>MWh/a</td><td>10% LR decrease                                                           </td><td>Vartiainen22</td><td>Page 4          </td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2020</td><td>Output|Hydrogen</td><td>Input|Electricity         </td><td> 0.67000000</td><td>      NA</td><td>MWh;LHV   </td><td>1</td><td>MWh  </td><td>1.5% of CAPEX; reported in units of electric capacity; 67% assumes the LHV</td><td>Vartiainen22</td><td>Page 4          </td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2030</td><td>Output|Hydrogen</td><td>Input|Electricity         </td><td> 0.70000000</td><td>      NA</td><td>MWh;LHV   </td><td>1</td><td>MWh  </td><td>10% LR decrease                                                           </td><td>Vartiainen22</td><td>Page 4          </td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2040</td><td>Output|Hydrogen</td><td>Input|Electricity         </td><td> 0.73000000</td><td>      NA</td><td>MWh;LHV   </td><td>1</td><td>MWh  </td><td>10% LR decrease                                                           </td><td>Vartiainen22</td><td>Page 4          </td></tr>\n",
       "\t<tr><td>Tech|Electrolysis</td><td>AEL</td><td>100 MW</td><td>*</td><td>2050</td><td>Output|Hydrogen</td><td>Input|Electricity         </td><td> 0.76000000</td><td>      NA</td><td>MWh;LHV   </td><td>1</td><td>MWh  </td><td>10% LR decrease                                                           </td><td>Vartiainen22</td><td>Page 4          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 12 x 15\n",
       "\\begin{tabular}{lllllllllllllll}\n",
       " parent\\_variable & subtech & size & region & period & variable & reference\\_variable & value & uncertainty & unit & reference\\_value & reference\\_unit & comment & source & source\\_detail\\\\\n",
       " <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl> & <chr> & <dbl> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2020 & CAPEX           & Input Capacity\\textbar{}Electricity & 45.40385963 & 0.000000 & USD\\_2005   & 1 & MWh/a &                                                                            & Vartiainen22 & Page 4, Figure 4\\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2030 & CAPEX           & Input Capacity\\textbar{}Electricity & 27.24231578 & 5.675482 & USD\\_2005   & 1 & MWh/a &                                                                            & Vartiainen22 & Page 4, Figure 4\\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2040 & CAPEX           & Input Capacity\\textbar{}Electricity & 15.89135087 & 8.513224 & USD\\_2005   & 1 & MWh/a &                                                                            & Vartiainen22 & Page 4, Figure 4\\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2050 & CAPEX           & Input Capacity\\textbar{}Electricity &  9.08077193 & 8.513224 & USD\\_2005   & 1 & MWh/a &                                                                            & Vartiainen22 & Page 4, Figure 4\\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2020 & OPEX Fixed      & Input Capacity\\textbar{}Electricity &  0.68105789 &       NA & USD\\_2005/a & 1 & MWh/a & 1.5\\% of CAPEX; reported in units of electric capacity                      & Vartiainen22 & Page 4          \\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2030 & OPEX Fixed      & Input Capacity\\textbar{}Electricity &  0.23837026 &       NA & USD\\_2005/a & 1 & MWh/a & 10\\% LR decrease                                                            & Vartiainen22 & Page 4          \\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2040 & OPEX Fixed      & Input Capacity\\textbar{}Electricity &  0.08286204 &       NA & USD\\_2005/a & 1 & MWh/a & 10\\% LR decrease                                                            & Vartiainen22 & Page 4          \\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2050 & OPEX Fixed      & Input Capacity\\textbar{}Electricity &  0.02837741 &       NA & USD\\_2005/a & 1 & MWh/a & 10\\% LR decrease                                                            & Vartiainen22 & Page 4          \\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2020 & Output\\textbar{}Hydrogen & Input\\textbar{}Electricity          &  0.67000000 &       NA & MWh;LHV    & 1 & MWh   & 1.5\\% of CAPEX; reported in units of electric capacity; 67\\% assumes the LHV & Vartiainen22 & Page 4          \\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2030 & Output\\textbar{}Hydrogen & Input\\textbar{}Electricity          &  0.70000000 &       NA & MWh;LHV    & 1 & MWh   & 10\\% LR decrease                                                            & Vartiainen22 & Page 4          \\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2040 & Output\\textbar{}Hydrogen & Input\\textbar{}Electricity          &  0.73000000 &       NA & MWh;LHV    & 1 & MWh   & 10\\% LR decrease                                                            & Vartiainen22 & Page 4          \\\\\n",
       "\t Tech\\textbar{}Electrolysis & AEL & 100 MW & * & 2050 & Output\\textbar{}Hydrogen & Input\\textbar{}Electricity          &  0.76000000 &       NA & MWh;LHV    & 1 & MWh   & 10\\% LR decrease                                                            & Vartiainen22 & Page 4          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 12 x 15\n",
       "\n",
       "| parent_variable &lt;chr&gt; | subtech &lt;chr&gt; | size &lt;chr&gt; | region &lt;chr&gt; | period &lt;chr&gt; | variable &lt;chr&gt; | reference_variable &lt;chr&gt; | value &lt;dbl&gt; | uncertainty &lt;dbl&gt; | unit &lt;chr&gt; | reference_value &lt;dbl&gt; | reference_unit &lt;chr&gt; | comment &lt;chr&gt; | source &lt;chr&gt; | source_detail &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2020 | CAPEX           | Input Capacity|Electricity | 45.40385963 | 0.000000 | USD_2005   | 1 | MWh/a | <!----> | Vartiainen22 | Page 4, Figure 4 |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2030 | CAPEX           | Input Capacity|Electricity | 27.24231578 | 5.675482 | USD_2005   | 1 | MWh/a | <!----> | Vartiainen22 | Page 4, Figure 4 |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2040 | CAPEX           | Input Capacity|Electricity | 15.89135087 | 8.513224 | USD_2005   | 1 | MWh/a | <!----> | Vartiainen22 | Page 4, Figure 4 |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2050 | CAPEX           | Input Capacity|Electricity |  9.08077193 | 8.513224 | USD_2005   | 1 | MWh/a | <!----> | Vartiainen22 | Page 4, Figure 4 |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2020 | OPEX Fixed      | Input Capacity|Electricity |  0.68105789 |       NA | USD_2005/a | 1 | MWh/a | 1.5% of CAPEX; reported in units of electric capacity                      | Vartiainen22 | Page 4           |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2030 | OPEX Fixed      | Input Capacity|Electricity |  0.23837026 |       NA | USD_2005/a | 1 | MWh/a | 10% LR decrease                                                            | Vartiainen22 | Page 4           |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2040 | OPEX Fixed      | Input Capacity|Electricity |  0.08286204 |       NA | USD_2005/a | 1 | MWh/a | 10% LR decrease                                                            | Vartiainen22 | Page 4           |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2050 | OPEX Fixed      | Input Capacity|Electricity |  0.02837741 |       NA | USD_2005/a | 1 | MWh/a | 10% LR decrease                                                            | Vartiainen22 | Page 4           |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2020 | Output|Hydrogen | Input|Electricity          |  0.67000000 |       NA | MWh;LHV    | 1 | MWh   | 1.5% of CAPEX; reported in units of electric capacity; 67% assumes the LHV | Vartiainen22 | Page 4           |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2030 | Output|Hydrogen | Input|Electricity          |  0.70000000 |       NA | MWh;LHV    | 1 | MWh   | 10% LR decrease                                                            | Vartiainen22 | Page 4           |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2040 | Output|Hydrogen | Input|Electricity          |  0.73000000 |       NA | MWh;LHV    | 1 | MWh   | 10% LR decrease                                                            | Vartiainen22 | Page 4           |\n",
       "| Tech|Electrolysis | AEL | 100 MW | * | 2050 | Output|Hydrogen | Input|Electricity          |  0.76000000 |       NA | MWh;LHV    | 1 | MWh   | 10% LR decrease                                                            | Vartiainen22 | Page 4           |\n",
       "\n"
      ],
      "text/plain": [
       "   parent_variable   subtech size   region period variable       \n",
       "1  Tech|Electrolysis AEL     100 MW *      2020   CAPEX          \n",
       "2  Tech|Electrolysis AEL     100 MW *      2030   CAPEX          \n",
       "3  Tech|Electrolysis AEL     100 MW *      2040   CAPEX          \n",
       "4  Tech|Electrolysis AEL     100 MW *      2050   CAPEX          \n",
       "5  Tech|Electrolysis AEL     100 MW *      2020   OPEX Fixed     \n",
       "6  Tech|Electrolysis AEL     100 MW *      2030   OPEX Fixed     \n",
       "7  Tech|Electrolysis AEL     100 MW *      2040   OPEX Fixed     \n",
       "8  Tech|Electrolysis AEL     100 MW *      2050   OPEX Fixed     \n",
       "9  Tech|Electrolysis AEL     100 MW *      2020   Output|Hydrogen\n",
       "10 Tech|Electrolysis AEL     100 MW *      2030   Output|Hydrogen\n",
       "11 Tech|Electrolysis AEL     100 MW *      2040   Output|Hydrogen\n",
       "12 Tech|Electrolysis AEL     100 MW *      2050   Output|Hydrogen\n",
       "   reference_variable         value       uncertainty unit      \n",
       "1  Input Capacity|Electricity 45.40385963 0.000000    USD_2005  \n",
       "2  Input Capacity|Electricity 27.24231578 5.675482    USD_2005  \n",
       "3  Input Capacity|Electricity 15.89135087 8.513224    USD_2005  \n",
       "4  Input Capacity|Electricity  9.08077193 8.513224    USD_2005  \n",
       "5  Input Capacity|Electricity  0.68105789       NA    USD_2005/a\n",
       "6  Input Capacity|Electricity  0.23837026       NA    USD_2005/a\n",
       "7  Input Capacity|Electricity  0.08286204       NA    USD_2005/a\n",
       "8  Input Capacity|Electricity  0.02837741       NA    USD_2005/a\n",
       "9  Input|Electricity           0.67000000       NA    MWh;LHV   \n",
       "10 Input|Electricity           0.70000000       NA    MWh;LHV   \n",
       "11 Input|Electricity           0.73000000       NA    MWh;LHV   \n",
       "12 Input|Electricity           0.76000000       NA    MWh;LHV   \n",
       "   reference_value reference_unit\n",
       "1  1               MWh/a         \n",
       "2  1               MWh/a         \n",
       "3  1               MWh/a         \n",
       "4  1               MWh/a         \n",
       "5  1               MWh/a         \n",
       "6  1               MWh/a         \n",
       "7  1               MWh/a         \n",
       "8  1               MWh/a         \n",
       "9  1               MWh           \n",
       "10 1               MWh           \n",
       "11 1               MWh           \n",
       "12 1               MWh           \n",
       "   comment                                                                   \n",
       "1                                                                            \n",
       "2                                                                            \n",
       "3                                                                            \n",
       "4                                                                            \n",
       "5  1.5% of CAPEX; reported in units of electric capacity                     \n",
       "6  10% LR decrease                                                           \n",
       "7  10% LR decrease                                                           \n",
       "8  10% LR decrease                                                           \n",
       "9  1.5% of CAPEX; reported in units of electric capacity; 67% assumes the LHV\n",
       "10 10% LR decrease                                                           \n",
       "11 10% LR decrease                                                           \n",
       "12 10% LR decrease                                                           \n",
       "   source       source_detail   \n",
       "1  Vartiainen22 Page 4, Figure 4\n",
       "2  Vartiainen22 Page 4, Figure 4\n",
       "3  Vartiainen22 Page 4, Figure 4\n",
       "4  Vartiainen22 Page 4, Figure 4\n",
       "5  Vartiainen22 Page 4          \n",
       "6  Vartiainen22 Page 4          \n",
       "7  Vartiainen22 Page 4          \n",
       "8  Vartiainen22 Page 4          \n",
       "9  Vartiainen22 Page 4          \n",
       "10 Vartiainen22 Page 4          \n",
       "11 Vartiainen22 Page 4          \n",
       "12 Vartiainen22 Page 4          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " DataSet$new('Tech|Electrolysis')$normalise(override=list('Tech|Electrolysis|Input Capacity|elec'= 'kW', 'Tech|Electrolysis|Output Capacity|h2'= 'kW;LHV'))  %>% filter(source=='Vartiainen22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DataSet$new('Tech|Electrolysis')$normalise(override=list('Tech|Electrolysis|Output Capacity|h2'= 'kW;LHV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DataSet$new('Tech|Electrolysis')$select(period=2020, subtech='AEL', size='100 MW', override=list('Tech|Electrolysis|Output Capacity|h2'= 'kW;LHV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DataSet$new('Tech|Electrolysis')$select(period=2030, source='Yates20', subtech='AEL', size='100 MW', override={'Tech|Electrolysis|Output Capacity|h2'= 'kW;LHV'}, extrapolate_period=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DataSet$new('Tech|Electrolysis')$select(subtech=c('AEL', 'PEM'), size='100 MW', override={'Tech|Electrolysis|Input Capacity|Electricity'= 'kW'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DataSet$new('Tech|Electrolysis')$aggregate(subtech='AEL', size='100 MW', agg='subtech', override={'Tech|Electrolysis|Output Capacity|Hydrogen'='kW;LHV'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# display(DataSet('Tech|Methane Reforming').aggregate(period=2030).query(\"variable.str.contains('OM Cost')\"))\n",
    "# display(DataSet('Tech|Methane Reforming').aggregate(period=2030).query(\"variable.str.contains('Demand')\"))\n",
    "DataSet$new('Tech|Methane Reforming')$aggregate(period=2030) %>% arrange(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DataSet$new('Tech|Direct Air Capture')$normalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DataSet$new('Tech|Direct Air Capture')$select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "TEDF$new('Tech|Haber-Bosch with ASU')$load()# $check()\n",
    "DataSet$new('Tech|Haber-Bosch with ASU')$normalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DataSet$new('Tech|Haber-Bosch with ASU')$select(period=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "DataSet$new('Tech|Haber-Bosch with ASU')$aggregate(period=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
